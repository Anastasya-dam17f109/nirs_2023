{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all was opened\n",
      "masks were drawen\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image,ImageOps,ImageStat,ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow  import keras as keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten, Activation, Conv2D, add, Concatenate\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import  ModelCheckpoint\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import os,os.path\n",
    "import sys\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "psp_fileName = \"D:/image_data_boundaries/__FR1_modified.jpg._PSP\"\n",
    "image_fileName = \"D:/image_data_boundaries/__FR1_modified.jpg\"\n",
    "newMask_fileName = \"D:/image_data_boundaries/new_mask_class_\"\n",
    "res_filename_winsize = \"D:/image_data_boundaries/homogen_parts\"\n",
    "fragm_dir = \"D:/image_data_boundaries/fragments\"\n",
    "param1 = 80\n",
    "#acc_file = 'D:/_SAR_Kubinka/accuracy.txt'\n",
    "result_fileName = \"D:/image_data_boundaries/classification_result\"\n",
    "#marks_filename = 'D:/_SAR_Kubinka/class_marks.txt'\n",
    "#img_len = 1024\n",
    "\n",
    "img_file_name = image_fileName\n",
    "#дополнять массив цветами по мере необходимости\\n\",\n",
    "t_color = ['red', 'blue']\n",
    "temple_file = Image.open(img_file_name)\n",
    "colors = {}\n",
    "#сборка границ прямоугольникв, из которых будут вырезаться области (если их на изображении несколько)\n",
    "classRects=[]\n",
    "curColor = \"\"\n",
    "class_numb = '021'\n",
    "rect_flag  = False\n",
    "   \n",
    "img = Image.new('RGB', temple_file.size, color=0)\n",
    "draw  = ImageDraw.Draw(img)\n",
    "fp = open(psp_fileName)\n",
    "print(\"all was opened\")\n",
    "for k, txt in enumerate(fp):\n",
    "    if k<2:\n",
    "        continue\n",
    "    zz, t = txt.split('=')\n",
    "    if t.find('Pline') >= 0:\n",
    "        x2y = []\n",
    "        rect_flag = False\n",
    "        continue\n",
    "    if t.find('Rectangle') >= 0:\n",
    "        x2y = []\n",
    "        rect_flag = True\n",
    "        continue\n",
    "    if t.find('Pen') >= 0:\n",
    "        p = t.split(',')\n",
    "        curColor = p[2]\n",
    "        if p[2] not in  colors:\n",
    "            colors.update({p[2]: len(colors)})\n",
    "   \n",
    "    t = t.split(' ')\n",
    "    if t[0] == '':\n",
    "        if rect_flag:\n",
    "            x2y.insert(1,(x2y[0][0],x2y[1][1]))\n",
    "            x2y.append( (x2y[2][0], x2y[0][1]))  \n",
    "        idx = colors.get(curColor) \n",
    "        if idx ==  len(classRects):\n",
    "            classRects.append([x2y])\n",
    "        else:\n",
    "            classRects[idx].append(x2y)\n",
    "        #print(classRects)   \n",
    "        draw.polygon(x2y, outline = t_color[idx], fill = t_color[idx])\n",
    "        continue\n",
    "    x2y.append((int(t[0]), int(t[1])))\n",
    "print(\"masks were drawen\")\n",
    "img.save(newMask_fileName + class_numb +\".BMP\")\n",
    "img.close()\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "win_size = 16\n",
    "step_len = 8\n",
    "bound = math.ceil(math.sqrt(2)*win_size-win_size)\n",
    "dir_name = fragm_dir\n",
    "labels=[]\n",
    "nmb_fragm = 0\n",
    "print(bound)\n",
    "im = Image.open(img_file_name)\n",
    "for i in range(len(colors)):\n",
    "    for j in range(len(classRects[i])):\n",
    "        \n",
    "        x0 = classRects[i][j][0][0]-step_len\n",
    "        y0 = classRects[i][j][0][1]-step_len\n",
    "        x_len =  classRects[i][j][1][1]-classRects[i][j][0][1]+step_len\n",
    "        y_len =  classRects[i][j][2][0]-classRects[i][j][1][0]+step_len\n",
    "        x_amount = int(x_len/step_len)\n",
    "        y_amount = int(y_len/step_len)\n",
    "        for k in range(x_amount):\n",
    "            for l in range(y_amount):\n",
    "                labels.append(i)\n",
    "               \n",
    "                im2=im.crop((x0 + k * step_len -bound, y0+ l * step_len -bound, x0 + k * step_len +bound + win_size,y0+ l * step_len +bound + win_size)) \n",
    "                imfnam=dir_name+\"\\\\+++fragm{:05d}.jpg\".format(nmb_fragm); \n",
    "                nmb_fragm+=1;\n",
    "                im2.save(imfnam)\n",
    "im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "858 856\n"
     ]
    }
   ],
   "source": [
    "gen_crop_img = True\n",
    "nmb_fragm = 0\n",
    "print(nmb_fragm)\n",
    "if gen_crop_img:\n",
    "    img = Image.open(img_file_name)\n",
    "    width, height = img.size\n",
    "    print(width, height)\n",
    "    with open (\"D:/image_data_boundaries/list_of_fragments.txt\", 'wt') as file:\n",
    "        for i in range(0, width, step_len):\n",
    "            for j in range(0, height, step_len):\n",
    "                if(i + win_size) < width and (j + win_size) < height:\n",
    "                    x2y = [(i, j), (i + win_size, j), (i + win_size, j + win_size), (i, j + win_size)]\n",
    "                    im2 = img.crop((i, j, i + win_size, j + win_size))\n",
    "                    imfnam = \"D:\\\\image_data_boundaries\\\\full_img\\\\+++fragm{:05d}.jpg\".format(nmb_fragm)\n",
    "                    file.write(imfnam + \" \" + str(i) + \" \" + str(j) + \"\\n\")\n",
    "                    nmb_fragm += 1;\n",
    "                    im2.save(imfnam)\n",
    "    img.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_in_list = True\n",
    "if load_in_list:\n",
    "    img_list = []\n",
    "    img_coords=[]\n",
    "    flag_read = True\n",
    "    with open(\"D:\\\\image_data_boundaries\\\\list_of_fragments.txt\", 'r') as file:\n",
    "        for bf in file:\n",
    "            bf_list = bf.split(\" \")\n",
    "            img_list.append(bf_list[0])\n",
    "            #print(img_list)\n",
    "            img_coords.append((int(bf_list[1]), int(bf_list[2])))\n",
    "            #print(bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_augm.shape= (23292, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "transAmount = 36;\n",
    "dlin   = 0\n",
    "\n",
    "def load_CNN_train_augment(dir_name1):\n",
    "    ll=[]           #пустой список имен входных файлов JPG \n",
    "    for file in os.listdir(dir_name1):\n",
    "        if file.endswith(\".jpg\"): ll.append(file)\n",
    "    dlin   = len(ll)     \n",
    "    dlin0  = int(len(ll)/2)  #будем пропускать нечетные элементы\n",
    "    #dlin=int(dlin0*(var+1) )  #0 ->просто чтение, 1 ->+90, 2 ->+180, 3 ->+270 дополняем массив\n",
    "    train_x = np.zeros((dlin * transAmount, win_size, win_size, 3), dtype='float32')\n",
    "    print('train_x_augm.shape=',train_x.shape)\n",
    "    train_z = np.zeros((dlin * transAmount, 1), dtype='float32')\n",
    "    dlin = dlin * transAmount\n",
    "    k=0\n",
    "    for file in ll:\n",
    "        im  = Image.open(dir_name+\"\\\\\"+file)\n",
    "        \n",
    "        shift0 = random.randint(0,7)\n",
    "        shift1 = random.randint(0,7)\n",
    "        shift2 = random.randint(0,7)\n",
    "        shift3 = random.randint(0,7)\n",
    "        #shift0 = 3\n",
    "        #shift1 = 3\n",
    "        #shift2 = 3\n",
    "        #shift3 = 3\n",
    "        '''\n",
    "        if shift0 == 0 and shift1 == 0:\n",
    "            shift0 += 2\n",
    "        if shift2 == 0 or shift2 == 3:    \n",
    "            shift2 +=1\n",
    "        if shift3 == 0 or shift3 == 3:    \n",
    "            shift3 +=1    \n",
    "        '''\n",
    "       \n",
    "        train_x[transAmount * k + 1] =np.array(im.crop((bound,bound,bound + win_size, bound +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 2] =np.array(im.rotate(90).crop((bound,bound,bound + win_size, bound +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 3] =np.array(im.rotate(45).crop((bound,bound,bound + win_size, bound +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 4] =np.array(im.rotate(30).crop((bound,bound,bound + win_size, bound +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 5] =np.array(im.rotate(75).crop((bound,bound,bound + win_size, bound +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 6] =np.array(im.rotate(180).crop((bound,bound,bound + win_size, bound +win_size)))*1./255.\n",
    "        \n",
    "        train_x[transAmount * k + 7] =np.array(im.crop((shift0,shift0,shift0 + win_size, shift0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 8] =np.array(im.rotate(90).crop((shift0,shift0,shift0 + win_size, shift0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 9] =np.array(im.rotate(45).crop((shift0,shift0,shift0 + win_size, shift0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 10] =np.array(im.rotate(30).crop((shift0,shift0,shift0 + win_size, shift0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 11] =np.array(im.rotate(75).crop((shift0,shift0,shift0 + win_size, shift0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 12] =np.array(im.rotate(180).crop((shift0,shift0,shift0 + win_size, shift0 +win_size)))*1./255.\n",
    "        \n",
    "        train_x[transAmount * k + 13] =np.array(im.crop((shift1,shift1,shift1 + win_size, shift1 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 14] =np.array(im.rotate(90).crop((shift1,shift1,shift1 + win_size, shift1 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 15] =np.array(im.rotate(45).crop((shift1,shift1,shift1 + win_size, shift1 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 16] =np.array(im.rotate(30).crop((shift1,shift1,shift1 + win_size, shift1 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 17] =np.array(im.rotate(75).crop((shift1,shift1,shift1 + win_size, shift1 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 18] =np.array(im.rotate(180).crop((shift1,shift1,shift1 + win_size, shift1 +win_size)))*1./255.\n",
    "        \n",
    "        train_x[transAmount * k + 19] =np.array(im.crop((shift2,shift2,shift2 + win_size, shift2 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 20] =np.array(im.rotate(90).crop((shift2,shift2,shift2 + win_size, shift2 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 21] =np.array(im.rotate(45).crop((shift2,shift2,shift2 + win_size, shift2 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 22] =np.array(im.rotate(30).crop((shift2,shift2,shift2 + win_size, shift2 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 23] =np.array(im.rotate(75).crop((shift2,shift2,shift2 + win_size, shift2 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 24] =np.array(im.rotate(180).crop((shift2,shift2,shift2 + win_size, shift2 +win_size)))*1./255.\n",
    "       \n",
    "        train_x[transAmount * k + 25] =np.array(im.crop((shift3,shift3,shift3 + win_size, shift3 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 26] =np.array(im.rotate(90).crop((shift3,shift3,shift3 + win_size, shift3 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 27] =np.array(im.rotate(45).crop((shift3,shift3,shift3 + win_size, shift3 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 28] =np.array(im.rotate(30).crop((shift3,shift3,shift3 + win_size, shift3 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 29] =np.array(im.rotate(75).crop((shift3,shift3,shift3 + win_size, shift3 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 0] =np.array(im.rotate(180).crop((shift3,shift3,shift3 + win_size, shift3 +win_size)))*1./255.\n",
    "        \n",
    "        train_x[transAmount * k + 30] =np.array(im.crop((shift3,0,shift3 + win_size, 0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 31] =np.array(im.rotate(90).crop((shift3,0,shift3 + win_size, 0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 32] =np.array(im.rotate(45).crop((shift3,0,shift3 + win_size, 0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 33] =np.array(im.rotate(30).crop((shift3,0,shift3 + win_size, 0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 34] =np.array(im.rotate(75).crop((shift3,0,shift3 + win_size, 0 +win_size)))*1./255.\n",
    "        train_x[transAmount * k + 35] =np.array(im.rotate(180).crop((shift3,0,shift3 + win_size, 0 +win_size)))*1./255.\n",
    "    #train_x[transAmount * k + 4] = np.array(im.crop((0,8,13,21)))*1./255.   \n",
    "        for i in range(transAmount):\n",
    "            train_z[k * transAmount + i] = int(labels[k])\n",
    "        \n",
    "        k+=1\n",
    "        if k==dlin: break\n",
    "    temp=[]\n",
    "    for i in range(len(train_z)):\n",
    "        temp.append(to_categorical(train_z[i],num_classes=len(colors)))\n",
    "    train_y=np.array(temp)    \n",
    "    return train_x,train_y\n",
    "\n",
    "train_x1,train_y1=load_CNN_train_augment(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_augm.shape= (1500, 1, 2)\n",
      "train_x_augm.shape= (21792, 16, 16, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 0.]],\n",
       "\n",
       "       [[1., 0.]],\n",
       "\n",
       "       [[1., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0.]],\n",
       "\n",
       "       [[0., 1.]],\n",
       "\n",
       "       [[1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount_valid = 1500\n",
    "k = 0\n",
    "idx_del = set()\n",
    "train_x_valid = np.zeros((amount_valid, win_size, win_size, 3), dtype='float32')\n",
    "train_y_valid = np.zeros((amount_valid,1,2), dtype='float32')\n",
    "while k < amount_valid:\n",
    "    idx = random.randint(0, train_x1.shape[0]-1)\n",
    "    while idx in idx_del:\n",
    "        idx = random.randint(0, train_x1.shape[0]-1)\n",
    "    idx_del.add(idx)\n",
    "    train_x_valid[k] = train_x1[idx]\n",
    "    train_y_valid[k] = train_y1[idx]\n",
    "    k += 1\n",
    "\n",
    "\n",
    "\n",
    "idx_del = list(idx_del)\n",
    "train_x_data1 = np.delete(train_x1, idx_del,0)\n",
    "train_y_data1 = np.delete(train_y1, idx_del,0)\n",
    "\n",
    "print('train_x_augm.shape=',train_y_valid.shape)\n",
    "print('train_x_augm.shape=',train_x_data1.shape)\n",
    "#реорганизация набора тестовых данных, чтобы была равномерность \n",
    "train_x_valid_buf = np.zeros((train_x_data1.shape[0]//2, win_size, win_size, 3), dtype='float32')\n",
    "train_y_valid_buf = np.zeros((train_x_data1.shape[0]//2,1,2), dtype='float32')\n",
    "\n",
    "for i in range(train_x_data1.shape[0]//2):\n",
    "    if i%2 ==0:\n",
    "        train_x_valid_buf[i] = train_x_data1[2*i]\n",
    "        train_y_valid_buf[i] = train_y_data1[2*i]\n",
    "np.flip( train_x_valid_buf)  \n",
    "np.flip( train_y_valid_buf)  \n",
    "for i in range(train_x_data1.shape[0]//2):\n",
    "    if i%2 ==0:\n",
    "        train_x_data1[2*i] = train_x_valid_buf[i]\n",
    "        train_y_data1[2*i] = train_y_valid_buf[i]\n",
    "train_x_data = np.zeros((train_x1.shape[0],win_size, win_size, 3), dtype='float32')  \n",
    "train_y_data = np.zeros((train_y1.shape[0],1,2), dtype='float32')  \n",
    "np.concatenate(( train_x_data1,train_x_valid),  out = train_x_data)    \n",
    "np.concatenate(( train_y_data1,train_y_valid),  out = train_y_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, height_et, width_et, depth_et = train_x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_4(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 30#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_5)\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_7)\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "    \n",
    "    conv_9 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_4)\n",
    "    conv_10 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_9)\n",
    "   # pool_5 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_10)\n",
    "    drop_5 = Dropout(drop_prob_1)(conv_10)\n",
    "    flat = Flatten()(drop_5)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_0(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 25#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , x1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "    x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_5)\n",
    "    conv_6 =add([conv_6 , x2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , x3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "   \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_1(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 30#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4, x1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "    x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_5)\n",
    "    conv_6 =add([conv_6 , x2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , x3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "    \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_2(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 20#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , x1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "    x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_5)\n",
    "    conv_6 =add([conv_6 , x2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , x3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "    \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN_model_ex(model_t,train_xt,train_yt,dlin_t,msize,step1,step2,val_split):\n",
    "    model_temp=model_t\n",
    "    val_acc_min=0.0\n",
    "    for k in range(step1):\n",
    "        #model_t.fit(train_xt,train_yt,epochs=step2,verbose=0,batch_size=16,validation_split=0.15)\n",
    "        hist=model_t.fit(train_xt,train_yt.squeeze(),epochs=1,verbose=0,validation_split = val_split, shuffle = True)#, callbacks=[mcp_save])\n",
    "        #print('First layer weights:', model.get_weights()[0])\n",
    "        vvv=hist.history['val_accuracy']\n",
    "        #vvv=hist.history['val_acc']\n",
    "        print(k,vvv)\n",
    "        val_acc = vvv[0]\n",
    "        if val_acc > val_acc_min:\n",
    "            model_temp = model_t\n",
    "            val_acc_min=val_acc\n",
    "            hist=model_t.fit(x=train_xt,y=train_yt.squeeze(),epochs=1,verbose=1,validation_split=val_split, shuffle = True, batch_size=64)#, callbacks=[mcp_save])#, callbacks=[mcp_save])\n",
    "        \n",
    "    #get_CNN_stat(train_xt,train_yt,dlin_t,model_t,msize)\n",
    "    #get_CNN_stat(train_xz,train_yz,dlin_t,model_t,msize)\n",
    "    print('end CNN train')\n",
    "    return model_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_5(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 25#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "   \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_6(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 25#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , x1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "    x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_5)\n",
    "    conv_6 =add([conv_6 , x2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , x3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "   \n",
    "    x4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_4)\n",
    "    conv_9 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_4)\n",
    "    conv_10 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    conv_10 =add([conv_10 , x4])\n",
    "    \n",
    "    drop_5 = Dropout(drop_prob_1)(conv_10 )\n",
    "    flat = Flatten()(drop_5)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_7(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 20#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "   \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_8(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 30#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size),padding='same')(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size),padding='same')(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size),padding='same')(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size),padding='same')(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "   \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_9(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 20#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='tanh')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='tanh')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "   \n",
    "    \n",
    "    flat = Flatten()(drop_4)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_10(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 20#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "    \n",
    "    conv_9 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_4)\n",
    "    conv_10 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_9)\n",
    "    conv_10 =add([conv_8 , drop_4])\n",
    "    #pool_5 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_10)\n",
    "    drop_5 = Dropout(drop_prob_1)(conv_10)\n",
    "    \n",
    "    flat = Flatten()(drop_5)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_11(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 20#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "    \n",
    "    conv_9 = Convolution2D(conv_depth_1-0, kernel_size, kernel_size, padding='same', activation='relu')(drop_4)\n",
    "    conv_10 = Convolution2D(conv_depth_1-0, kernel_size, kernel_size, padding='same', activation='relu')(conv_9)\n",
    "    #conv_10 =add([conv_8 , drop_4])\n",
    "    #pool_5 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_10)\n",
    "    drop_5 = Dropout(drop_prob_1)(conv_10)\n",
    "    \n",
    "    flat = Flatten()(drop_5)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_cnn_model_12(height,width,depth):\n",
    "    batch_size = 8 # in each iteration, we consider 32 training examples at once\n",
    "    num_epochs = 2 # we iterate 200 times over the entire training set\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 25#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    conv_depth_2 = height #64 # ...switching to 64 after the first pooling layer\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "    hidden_size = 68 # the FC layer will have 512 neurons\n",
    "    num_classes=2\n",
    "\n",
    "    inp = Input(shape=(height, width,depth)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='tanh')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "   # x1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(drop_1)\n",
    "    conv_4 = Convolution2D(conv_depth_1, kernel_size, kernel_size, padding='same', activation='relu')(conv_3)\n",
    "    conv_4 =add([conv_4 , drop_1])\n",
    "    pool_2 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    \n",
    "    \n",
    "   # x2 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_2)\n",
    "    conv_5 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_2)\n",
    "    conv_6 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_5)\n",
    "    #conv_6 =add([conv_6 , drop_2])\n",
    "    pool_3 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_6)\n",
    "    drop_3 = Dropout(drop_prob_1)(pool_3)\n",
    "    \n",
    "    #x3 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_3)\n",
    "    conv_7 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(drop_3)\n",
    "    conv_8 = Convolution2D(conv_depth_1-10, kernel_size, kernel_size, padding='same', activation='relu')(conv_7)\n",
    "    conv_8 =add([conv_8 , drop_3])\n",
    "    pool_4 = MaxPooling2D(pool_size = (pool_size, pool_size), padding='same')(conv_8)\n",
    "    drop_4 = Dropout(drop_prob_1)(pool_4)\n",
    "    \n",
    "    conv_9 = Convolution2D(conv_depth_1-0, kernel_size, kernel_size, padding='same', activation='relu')(drop_4)\n",
    "    conv_10 = Convolution2D(conv_depth_1-0, kernel_size, kernel_size, padding='same', activation='relu')(conv_9)\n",
    "    #conv_10 =add([conv_8 , drop_4])\n",
    "    #pool_5 = MaxPooling2D(pool_size = (pool_size, pool_size))(conv_10)\n",
    "    drop_5 = Dropout(drop_prob_1)(conv_10)\n",
    "    \n",
    "    flat = Flatten()(drop_5)\n",
    "   \n",
    "    #flat= pool_1\n",
    "    #out = Dense(hidden_size, activation='tanh')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "    #dense1 = Dense(20, activation='sigmoid')(flat)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out) # To define a model, just specify its input and output layers\n",
    "    model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_img_by_batch(model, filename_suffix, res_fname_suffix):\n",
    "    temple_file = Image.open(img_file_name)\n",
    "    img = Image.new('RGB', temple_file.size, color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "    class_marks = np.zeros((width, height), dtype='int')\n",
    "    batch_size_t = 32\n",
    "    batch_count = 0\n",
    "    batch_pack = np.zeros((batch_size_t , win_size, win_size, 3), dtype='float32')\n",
    "    batch_coords = []\n",
    "    idx_counter = 0\n",
    "    with open(res_filename_winsize + res_fname_suffix, 'w') as file:\n",
    "        for i in img_list:\n",
    "\n",
    "\n",
    "            if(batch_count < batch_size_t ):\n",
    "                im = Image.open(i)\n",
    "\n",
    "                #print(img_coords[idx_counter])\n",
    "                batch_pack[batch_count] = np.array(im)*1./255.\n",
    "                #print(batch_pack[batch_count])\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "            else:\n",
    "                #pred_res = model.predict_on_batch(batch_pack)\n",
    "                pred_res = model.predict(batch_pack,batch_size=batch_size_t )\n",
    "                print(pred_res)\n",
    "                for j in range(pred_res.shape[0]):\n",
    "                    i_idx = batch_coords[j][0]\n",
    "                    j_idx = batch_coords[j][1]\n",
    "                    max_idx = np.argmax(pred_res[j])\n",
    "                    #if max_idx == 0:\n",
    "                       # max_idx = 1\n",
    "                   # else:\n",
    "                        #max_idx = 0\n",
    "                    file.write(str(i_idx) + \" \" + str( height - j_idx ) + \" \" + str(max_idx) + \"\\n\")\n",
    "                    for k in range(win_size):\n",
    "                        for l in range(win_size):\n",
    "                            class_marks[i_idx + k, j_idx + l] = max_idx\n",
    "                    draw.polygon([(i_idx, j_idx), (i_idx + win_size, j_idx), (i_idx + win_size, j_idx+ win_size), (i_idx, j_idx + win_size)], outline=t_color[max_idx], fill=t_color[max_idx])\n",
    "                batch_count = 0\n",
    "                batch_coords = []\n",
    "                im = Image.open(i)\n",
    "                #print(i)\n",
    "                #print(img_coords[idx_counter])\n",
    "                batch_pack[batch_count] = np.array(im)*1./255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "    file.close()  \n",
    "    img.save(result_fileName + filename_suffix)\n",
    "    img.close()\n",
    "    return class_marks\n",
    "\n",
    "def classify_flat(model, filename_suffix):\n",
    "    temple_file = Image.open(img_file_name)\n",
    "    img = Image.new('RGB', temple_file.size, color=0)\n",
    "    x0 = 0\n",
    "    y0 = 0\n",
    "    draw  = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "    im2 = np.zeros((1, win_size, win_size, 3), dtype='float32')\n",
    "    class_marks = np.zeros((width,height), dtype='int')\n",
    "    for i in range(0, width,step_len ):\n",
    "        for j in range(0, height,step_len):\n",
    "            if(i + win_size) < width and (j + win_size ) < height:\n",
    "                x2y = [(i,j), (i + win_size, j),(i + win_size, j + win_size), (i, j + win_size)]\n",
    "                im2[0] = np.array(  temple_file.crop((i, j, i + win_size,j + win_size)))*1./255.\n",
    "                z = model1.predict(im2)\n",
    "                m_idx = np.argmax(z[0])\n",
    "                for k in range(win_size):\n",
    "                    for l in range(win_size):\n",
    "                        class_marks[i + k, j + l] = m_idx\n",
    "                draw.polygon(x2y, outline = t_color[m_idx], fill = t_color[m_idx])\n",
    "\n",
    "    img.save(result_fileName + filename_suffix)\n",
    "    img.close()\n",
    "    return class_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_img_by_batch_res_UDP(model, filename_suffix, res_fname_suffix):\n",
    "    temple_file = Image.open(img_file_name)\n",
    "    img = Image.new('RGB', temple_file.size, color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "    class_marks = np.zeros((width, height), dtype='int')\n",
    "    batch_size_t = 32\n",
    "    batch_count = 0\n",
    "    batch_pack = np.zeros((batch_size_t , win_size, win_size, 3), dtype='float32')\n",
    "    batch_coords = []\n",
    "    idx_counter = 0\n",
    "    homogen_parts = {}\n",
    "    with open(res_filename_winsize + res_fname_suffix, 'w') as file:\n",
    "        for i in img_list:\n",
    "            if(batch_count < batch_size_t ):\n",
    "                im = Image.open(i)\n",
    "                batch_pack[batch_count] = np.array(im)*1./255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "            else:\n",
    "                pred_res = model.predict(batch_pack,batch_size=batch_size_t )\n",
    "                \n",
    "                for j in range(pred_res.shape[0]):\n",
    "                    i_idx = batch_coords[j][0]\n",
    "                    j_idx = batch_coords[j][1]\n",
    "                   #print(i_idx, j_idx)\n",
    "                    max_idx = np.argmax(pred_res[j])\n",
    "                    #if max_idx == 0:\n",
    "                       # max_idx = 1\n",
    "                   # else:\n",
    "                        #max_idx = 0\n",
    "                    homogen_parts[(i_idx,height - j_idx)]=max_idx\n",
    "                    #file.write(str(i_idx) + \" \" + str( height - j_idx ) + \" \" + str(max_idx) + \"\\n\")\n",
    "                    #for k in range(win_size):\n",
    "                        #for l in range(win_size):\n",
    "                            #class_marks[i_idx + k, j_idx + l] = max_idx\n",
    "                    #draw.polygon([(i_idx, j_idx), (i_idx + win_size, j_idx), (i_idx + win_size, j_idx+ win_size), (i_idx, j_idx + win_size)], outline=t_color[max_idx], fill=t_color[max_idx])\n",
    "                batch_count = 0\n",
    "                batch_coords = []\n",
    "                im = Image.open(i)\n",
    "                #print(i)\n",
    "                #print(img_coords[idx_counter])\n",
    "                batch_pack[batch_count] = np.array(im)*1./255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "        for i in homogen_parts:\n",
    "            i_idx = i[0]\n",
    "            j_idx = height - i[1]\n",
    "            elem_amount = 0\n",
    "            summ = 0\n",
    "            \n",
    "            if (i_idx-step_len, j_idx) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx-step_len, j_idx)]\n",
    "            if (i_idx + step_len, j_idx) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx + step_len, j_idx)]\n",
    "            if (i_idx, j_idx-step_len) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx, j_idx-step_len)]\n",
    "            if (i_idx , j_idx+ step_len) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx , j_idx + step_len)]\n",
    "\n",
    "            if elem_amount == 4:\n",
    "                if summ == 0 or summ == 1:\n",
    "                    homogen_parts.update({(i_idx, j_idx): 0})\n",
    "                if summ == 3 or summ == 4:\n",
    "                    homogen_parts.update({(i_idx, j_idx): 1})\n",
    "            if elem_amount == 3:\n",
    "                if summ == 0 or summ == 1:\n",
    "                    homogen_parts.update({(i_idx, j_idx): 0})\n",
    "                if summ == 3 :\n",
    "                    homogen_parts.update({(i_idx, j_idx): 1})\n",
    "            \n",
    "        #print(homogen_parts)\n",
    "        #print( homogen_parts.get((0, 0)))\n",
    "        for i in homogen_parts:\n",
    "            i_idx = i[0]\n",
    "            j_idx = height - i[1]\n",
    "            file.write(str(i_idx) + \" \" + str(  i[1] ) + \" \" + str(homogen_parts[(i_idx,  i[1])]) + \"\\n\")\n",
    "            for k in range(win_size):\n",
    "                for l in range(win_size):\n",
    "                    class_marks[i_idx + k, j_idx + l] = homogen_parts[(i_idx,  i[1])]\n",
    "            draw.polygon([(i_idx, j_idx), (i_idx + win_size, j_idx), (i_idx + win_size, j_idx+ win_size), (i_idx, j_idx + win_size)], outline=t_color[homogen_parts[(i_idx,  i[1])]], fill=t_color[homogen_parts[(i_idx,  i[1])]])\n",
    "    file.close()\n",
    "    img.save(result_fileName + filename_suffix)\n",
    "    img.close()\n",
    "    return class_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_img_by_batch_res_UDP_modified(model, filename_suffix, res_fname_suffix):\n",
    "    temple_file = Image.open(img_file_name)\n",
    "    img = Image.new('RGB', temple_file.size, color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "    class_marks = np.zeros((width, height), dtype='int')\n",
    "    batch_size_t = 32\n",
    "    batch_count = 0\n",
    "    batch_pack = np.zeros((batch_size_t , win_size, win_size, 3), dtype='float32')\n",
    "    batch_coords = []\n",
    "    idx_counter = 0\n",
    "    homogen_parts = {}\n",
    "    with open(res_filename_winsize + res_fname_suffix, 'w') as file:\n",
    "        for i in img_list:\n",
    "            if(batch_count < batch_size_t ):\n",
    "                im = Image.open(i)\n",
    "                batch_pack[batch_count] = np.array(im)*1./255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "            else:\n",
    "                pred_res = model.predict(batch_pack,batch_size=batch_size_t )\n",
    "                \n",
    "                for j in range(pred_res.shape[0]):\n",
    "                    i_idx = batch_coords[j][0]\n",
    "                    j_idx = batch_coords[j][1]\n",
    "                   #print(i_idx, j_idx)\n",
    "                    max_idx = np.argmax(pred_res[j])\n",
    "                    #if max_idx == 0:\n",
    "                       # max_idx = 1\n",
    "                   # else:\n",
    "                        #max_idx = 0\n",
    "                    homogen_parts[(i_idx,height - j_idx)]=max_idx\n",
    "                    #file.write(str(i_idx) + \" \" + str( height - j_idx ) + \" \" + str(max_idx) + \"\\n\")\n",
    "                    #for k in range(win_size):\n",
    "                        #for l in range(win_size):\n",
    "                            #class_marks[i_idx + k, j_idx + l] = max_idx\n",
    "                    #draw.polygon([(i_idx, j_idx), (i_idx + win_size, j_idx), (i_idx + win_size, j_idx+ win_size), (i_idx, j_idx + win_size)], outline=t_color[max_idx], fill=t_color[max_idx])\n",
    "                batch_count = 0\n",
    "                batch_coords = []\n",
    "                im = Image.open(i)\n",
    "                #print(i)\n",
    "                #print(img_coords[idx_counter])\n",
    "                batch_pack[batch_count] = np.array(im)*1./255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "        for i in homogen_parts:\n",
    "            i_idx = i[0]\n",
    "            j_idx = height - i[1]\n",
    "            elem_amount = 0\n",
    "            summ = 0\n",
    "            \n",
    "            if (i_idx-step_len, j_idx) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx-step_len, j_idx)]\n",
    "            if (i_idx + step_len, j_idx) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx + step_len, j_idx)]\n",
    "            if (i_idx, j_idx-step_len) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx, j_idx-step_len)]\n",
    "            if (i_idx , j_idx+ step_len) in homogen_parts:\n",
    "                elem_amount += 1\n",
    "                summ += homogen_parts[(i_idx , j_idx + step_len)]\n",
    "\n",
    "            if elem_amount == 4:\n",
    "                if summ == 0 :#or summ == 1:\n",
    "                    homogen_parts.update({(i_idx, j_idx): 0})\n",
    "                if summ == 4:\n",
    "                    homogen_parts.update({(i_idx, j_idx): 1})\n",
    "            if elem_amount == 3:\n",
    "                if summ == 0 :\n",
    "                    homogen_parts.update({(i_idx, j_idx): 0})\n",
    "                if summ == 3 :\n",
    "                    homogen_parts.update({(i_idx, j_idx): 1})\n",
    "            \n",
    "        #print(homogen_parts)\n",
    "        #print( homogen_parts.get((0, 0)))\n",
    "        for i in homogen_parts:\n",
    "            i_idx = i[0]\n",
    "            j_idx = height - i[1]\n",
    "            file.write(str(i_idx) + \" \" + str(  i[1] ) + \" \" + str(homogen_parts[(i_idx,  i[1])]) + \"\\n\")\n",
    "            for k in range(win_size):\n",
    "                for l in range(win_size):\n",
    "                    class_marks[i_idx + k, j_idx + l] = homogen_parts[(i_idx,  i[1])]\n",
    "            draw.polygon([(i_idx, j_idx), (i_idx + win_size, j_idx), (i_idx + win_size, j_idx+ win_size), (i_idx, j_idx + win_size)], outline=t_color[homogen_parts[(i_idx,  i[1])]], fill=t_color[homogen_parts[(i_idx,  i[1])]])\n",
    "    file.close()\n",
    "    img.save(result_fileName + filename_suffix)\n",
    "    img.close()\n",
    "    return class_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.41716739535331726]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5675 - accuracy: 0.6944 - val_loss: 0.6679 - val_accuracy: 0.4528\n",
      "1 [0.6244634985923767]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5235 - accuracy: 0.7127 - val_loss: 0.6033 - val_accuracy: 0.7476\n",
      "2 [0.7682403326034546]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5098 - accuracy: 0.7215 - val_loss: 0.5574 - val_accuracy: 0.7661\n",
      "3 [0.7686695456504822]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5055 - accuracy: 0.7230 - val_loss: 0.5547 - val_accuracy: 0.7837\n",
      "4 [0.7283262014389038]\n",
      "5 [0.7682403326034546]\n",
      "6 [0.7682403326034546]\n",
      "7 [0.7768240571022034]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4839 - accuracy: 0.7351 - val_loss: 0.4935 - val_accuracy: 0.7863\n",
      "8 [0.7914162874221802]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4815 - accuracy: 0.7351 - val_loss: 0.5123 - val_accuracy: 0.7876\n",
      "9 [0.7922746539115906]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4769 - accuracy: 0.7383 - val_loss: 0.4858 - val_accuracy: 0.7996\n",
      "10 [0.790128767490387]\n",
      "11 [0.7854077219963074]\n",
      "12 [0.7884120345115662]\n",
      "13 [0.8051502108573914]\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.4710 - accuracy: 0.7412 - val_loss: 0.5031 - val_accuracy: 0.8107\n",
      "14 [0.7991416454315186]\n",
      "15 [0.7978540658950806]\n",
      "16 [0.795708179473877]\n",
      "17 [0.8004291653633118]\n",
      "18 [0.795708179473877]\n",
      "19 [0.8103004097938538]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4629 - accuracy: 0.7446 - val_loss: 0.4826 - val_accuracy: 0.8056\n",
      "20 [0.785836935043335]\n",
      "21 [0.8077253103256226]\n",
      "22 [0.7828326225280762]\n",
      "23 [0.7922746539115906]\n",
      "24 [0.8090128898620605]\n",
      "25 [0.8051502108573914]\n",
      "26 [0.7982832789421082]\n",
      "27 [0.8017167448997498]\n",
      "28 [0.8111587762832642]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4572 - accuracy: 0.7473 - val_loss: 0.4797 - val_accuracy: 0.8232\n",
      "29 [0.7995707988739014]\n",
      "30 [0.8133047223091125]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4497 - accuracy: 0.7488 - val_loss: 0.4905 - val_accuracy: 0.8103\n",
      "31 [0.808583676815033]\n",
      "32 [0.8025751113891602]\n",
      "33 [0.8017167448997498]\n",
      "34 [0.8090128898620605]\n",
      "35 [0.8072961568832397]\n",
      "36 [0.8021458983421326]\n",
      "37 [0.8081545233726501]\n",
      "38 [0.8012875318527222]\n",
      "39 [0.8021458983421326]\n",
      "40 [0.8223176002502441]\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.4433 - accuracy: 0.7544 - val_loss: 0.4790 - val_accuracy: 0.8120\n",
      "41 [0.8012875318527222]\n",
      "42 [0.8008583784103394]\n",
      "43 [0.8068669438362122]\n",
      "44 [0.8115879893302917]\n",
      "45 [0.8072961568832397]\n",
      "46 [0.8060085773468018]\n",
      "47 [0.804291844367981]\n",
      "48 [0.8021458983421326]\n",
      "49 [0.7836909890174866]\n",
      "50 [0.8133047223091125]\n",
      "51 [0.8094420433044434]\n",
      "52 [0.8060085773468018]\n",
      "53 [0.7948498129844666]\n",
      "54 [0.798712432384491]\n",
      "55 [0.805579423904419]\n",
      "56 [0.8072961568832397]\n",
      "57 [0.8021458983421326]\n",
      "58 [0.7991416454315186]\n",
      "59 [0.803004264831543]\n",
      "60 [0.8064377903938293]\n",
      "61 [0.8004291653633118]\n",
      "62 [0.8025751113891602]\n",
      "63 [0.7995707988739014]\n",
      "64 [0.7978540658950806]\n",
      "65 [0.803004264831543]\n",
      "66 [0.8103004097938538]\n",
      "67 [0.8115879893302917]\n",
      "68 [0.800000011920929]\n",
      "69 [0.8051502108573914]\n",
      "70 [0.8107296228408813]\n",
      "71 [0.812875509262085]\n",
      "72 [0.8034334778785706]\n",
      "73 [0.8090128898620605]\n",
      "74 [0.8004291653633118]\n",
      "75 [0.804291844367981]\n",
      "76 [0.795708179473877]\n",
      "77 [0.809871256351471]\n",
      "78 [0.8103004097938538]\n",
      "79 [0.7969956994056702]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=def_cnn_model_7(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 80\n",
    "model1=train_CNN_model_ex(model1,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model1, \"_7_1.BMP\",\"_7_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.43261802196502686]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5657 - accuracy: 0.7053 - val_loss: 0.6618 - val_accuracy: 0.4262\n",
      "1 [0.43304720520973206]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5321 - accuracy: 0.7137 - val_loss: 0.6494 - val_accuracy: 0.4335\n",
      "2 [0.43304720520973206]\n",
      "3 [0.43347638845443726]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.7149 - val_loss: 0.6162 - val_accuracy: 0.4361\n",
      "4 [0.43218883872032166]\n",
      "5 [0.43433475494384766]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7122 - val_loss: 0.6494 - val_accuracy: 0.4361\n",
      "6 [0.43476393818855286]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4950 - accuracy: 0.7190 - val_loss: 0.5910 - val_accuracy: 0.4356\n",
      "7 [0.43648070096969604]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4942 - accuracy: 0.7170 - val_loss: 0.5915 - val_accuracy: 0.4365\n",
      "8 [0.43390557169914246]\n",
      "9 [0.43605148792266846]\n",
      "10 [0.43605148792266846]\n",
      "11 [0.43519312143325806]\n",
      "12 [0.7502145767211914]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4953 - accuracy: 0.7212 - val_loss: 0.6025 - val_accuracy: 0.7326\n",
      "13 [0.7600858211517334]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4780 - accuracy: 0.7274 - val_loss: 0.5839 - val_accuracy: 0.7506\n",
      "14 [0.43776825070381165]\n",
      "15 [0.43605148792266846]\n",
      "16 [0.43819743394851685]\n",
      "17 [0.43733906745910645]\n",
      "18 [0.43648070096969604]\n",
      "19 [0.6862660646438599]\n",
      "20 [0.43648070096969604]\n",
      "21 [0.7725321650505066]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4662 - accuracy: 0.7280 - val_loss: 0.6278 - val_accuracy: 0.7451\n",
      "22 [0.7510729432106018]\n",
      "23 [0.6583691239356995]\n",
      "24 [0.769098699092865]\n",
      "25 [0.7175965905189514]\n",
      "26 [0.7124463319778442]\n",
      "27 [0.711158812046051]\n",
      "28 [0.7433476448059082]\n",
      "29 [0.759227454662323]\n",
      "30 [0.7103004455566406]\n",
      "31 [0.736480712890625]\n",
      "32 [0.6952789425849915]\n",
      "33 [0.7278969883918762]\n",
      "34 [0.6828325986862183]\n",
      "35 [0.6854076981544495]\n",
      "36 [0.7682403326034546]\n",
      "37 [0.6789699792861938]\n",
      "38 [0.7579399347305298]\n",
      "39 [0.7909871339797974]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4559 - accuracy: 0.7382 - val_loss: 0.6484 - val_accuracy: 0.7210\n",
      "40 [0.7682403326034546]\n",
      "41 [0.7454935908317566]\n",
      "42 [0.780257523059845]\n",
      "43 [0.7360514998435974]\n",
      "44 [0.7429184317588806]\n",
      "45 [0.7793991565704346]\n",
      "46 [0.7317596673965454]\n",
      "47 [0.749356210231781]\n",
      "48 [0.775965690612793]\n",
      "49 [0.749356210231781]\n",
      "50 [0.7459227442741394]\n",
      "51 [0.7665235996246338]\n",
      "52 [0.7978540658950806]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4474 - accuracy: 0.7442 - val_loss: 0.5987 - val_accuracy: 0.7348\n",
      "53 [0.7751073241233826]\n",
      "54 [0.7652360796928406]\n",
      "55 [0.7403433322906494]\n",
      "56 [0.769098699092865]\n",
      "57 [0.7304720878601074]\n",
      "58 [0.756223201751709]\n",
      "59 [0.7708154320716858]\n",
      "60 [0.769098699092865]\n",
      "61 [0.6605150103569031]\n",
      "62 [0.7699570655822754]\n",
      "63 [0.7300429344177246]\n",
      "64 [0.774678111076355]\n",
      "65 [0.7330471873283386]\n",
      "66 [0.739484965801239]\n",
      "67 [0.7652360796928406]\n",
      "68 [0.7519313097000122]\n",
      "69 [0.745064377784729]\n",
      "70 [0.7304720878601074]\n",
      "71 [0.769098699092865]\n",
      "72 [0.7695279121398926]\n",
      "73 [0.7896995544433594]\n",
      "74 [0.721030056476593]\n",
      "75 [0.7755364775657654]\n",
      "76 [0.7995707988739014]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4407 - accuracy: 0.7508 - val_loss: 0.5835 - val_accuracy: 0.7665\n",
      "77 [0.733905553817749]\n",
      "78 [0.735193133354187]\n",
      "79 [0.7540772557258606]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_9(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 80\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_9.BMP\", \"_9.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.42060086131095886]\n",
      "328/328 [==============================] - 6s 18ms/step - loss: 0.5715 - accuracy: 0.6800 - val_loss: 0.6749 - val_accuracy: 0.4708\n",
      "1 [0.43433475494384766]\n",
      "328/328 [==============================] - 6s 19ms/step - loss: 0.5246 - accuracy: 0.7014 - val_loss: 0.6360 - val_accuracy: 0.4747\n",
      "2 [0.43047210574150085]\n",
      "3 [0.43004292249679565]\n",
      "4 [0.43347638845443726]\n",
      "5 [0.694420576095581]\n",
      "328/328 [==============================] - 6s 17ms/step - loss: 0.4974 - accuracy: 0.7182 - val_loss: 0.5913 - val_accuracy: 0.7309\n",
      "6 [0.6472102999687195]\n",
      "7 [0.7609441876411438]\n",
      "328/328 [==============================] - 6s 17ms/step - loss: 0.4912 - accuracy: 0.7273 - val_loss: 0.5857 - val_accuracy: 0.7618\n",
      "8 [0.7497854232788086]\n",
      "9 [0.7618025541305542]\n",
      "328/328 [==============================] - 6s 17ms/step - loss: 0.4920 - accuracy: 0.7249 - val_loss: 0.5793 - val_accuracy: 0.7691\n",
      "10 [0.7214592099189758]\n",
      "11 [0.7223175764083862]\n",
      "12 [0.7248926758766174]\n",
      "13 [0.6991416215896606]\n",
      "14 [0.7304720878601074]\n",
      "15 [0.7021459341049194]\n",
      "16 [0.7875536680221558]\n",
      "328/328 [==============================] - 6s 18ms/step - loss: 0.4807 - accuracy: 0.7331 - val_loss: 0.5692 - val_accuracy: 0.7584\n",
      "17 [0.7570815682411194]\n",
      "18 [0.784549355506897]\n",
      "19 [0.7841201424598694]\n",
      "20 [0.7841201424598694]\n",
      "21 [0.7785407900810242]\n",
      "22 [0.7424892783164978]\n",
      "23 [0.7699570655822754]\n",
      "24 [0.7866953015327454]\n",
      "25 [0.790128767490387]\n",
      "328/328 [==============================] - 6s 19ms/step - loss: 0.4710 - accuracy: 0.7403 - val_loss: 0.5515 - val_accuracy: 0.7824\n",
      "26 [0.7862660884857178]\n",
      "27 [0.7922746539115906]\n",
      "328/328 [==============================] - 6s 18ms/step - loss: 0.4679 - accuracy: 0.7406 - val_loss: 0.5469 - val_accuracy: 0.7901\n",
      "28 [0.7682403326034546]\n",
      "29 [0.770386278629303]\n",
      "30 [0.7918455004692078]\n",
      "31 [0.7896995544433594]\n",
      "32 [0.7751073241233826]\n",
      "33 [0.788841187953949]\n",
      "34 [0.7785407900810242]\n",
      "35 [0.7866953015327454]\n",
      "36 [0.7738197445869446]\n",
      "37 [0.769098699092865]\n",
      "38 [0.7768240571022034]\n",
      "39 [0.7819742560386658]\n",
      "40 [0.7892704010009766]\n",
      "41 [0.7793991565704346]\n",
      "42 [0.7978540658950806]\n",
      "328/328 [==============================] - 5s 16ms/step - loss: 0.4587 - accuracy: 0.7478 - val_loss: 0.5442 - val_accuracy: 0.7798\n",
      "43 [0.7738197445869446]\n",
      "44 [0.7819742560386658]\n",
      "45 [0.7815450429916382]\n",
      "46 [0.7815450429916382]\n",
      "47 [0.7836909890174866]\n",
      "48 [0.7772532105445862]\n",
      "49 [0.7824034094810486]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 317us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_10(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 50\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_10_1.BMP\",\"_10_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.3905579447746277]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.5813 - accuracy: 0.6616 - val_loss: 0.6650 - val_accuracy: 0.5210\n",
      "1 [0.46394848823547363]\n",
      "328/328 [==============================] - 2s 4ms/step - loss: 0.5108 - accuracy: 0.7040 - val_loss: 0.6611 - val_accuracy: 0.5155\n",
      "2 [0.5974248647689819]\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.4953 - accuracy: 0.7142 - val_loss: 0.6292 - val_accuracy: 0.6991\n",
      "3 [0.5463519096374512]\n",
      "4 [0.7570815682411194]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4872 - accuracy: 0.7188 - val_loss: 0.6007 - val_accuracy: 0.7395\n",
      "5 [0.6309012770652771]\n",
      "6 [0.7523605227470398]\n",
      "7 [0.736480712890625]\n",
      "8 [0.7579399347305298]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4774 - accuracy: 0.7280 - val_loss: 0.5880 - val_accuracy: 0.7330\n",
      "9 [0.7334764003753662]\n",
      "10 [0.794420599937439]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4690 - accuracy: 0.7354 - val_loss: 0.5770 - val_accuracy: 0.7652\n",
      "11 [0.7815450429916382]\n",
      "12 [0.7716737985610962]\n",
      "13 [0.7403433322906494]\n",
      "14 [0.726609468460083]\n",
      "15 [0.7497854232788086]\n",
      "16 [0.756223201751709]\n",
      "17 [0.7729613780975342]\n",
      "18 [0.788841187953949]\n",
      "19 [0.7424892783164978]\n",
      "20 [0.7948498129844666]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4609 - accuracy: 0.7371 - val_loss: 0.5543 - val_accuracy: 0.7948\n",
      "21 [0.7965665459632874]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4598 - accuracy: 0.7365 - val_loss: 0.5722 - val_accuracy: 0.7528\n",
      "22 [0.746351957321167]\n",
      "23 [0.773390531539917]\n",
      "24 [0.8012875318527222]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4595 - accuracy: 0.7422 - val_loss: 0.5523 - val_accuracy: 0.7644\n",
      "25 [0.7978540658950806]\n",
      "26 [0.7781115770339966]\n",
      "27 [0.7566523551940918]\n",
      "28 [0.8017167448997498]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4520 - accuracy: 0.7484 - val_loss: 0.5375 - val_accuracy: 0.8052\n",
      "29 [0.7386265993118286]\n",
      "30 [0.7824034094810486]\n",
      "31 [0.7566523551940918]\n",
      "32 [0.7815450429916382]\n",
      "33 [0.7699570655822754]\n",
      "34 [0.7965665459632874]\n",
      "35 [0.7824034094810486]\n",
      "36 [0.7579399347305298]\n",
      "37 [0.7665235996246338]\n",
      "38 [0.8021458983421326]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4472 - accuracy: 0.7482 - val_loss: 0.5379 - val_accuracy: 0.7790\n",
      "39 [0.7914162874221802]\n",
      "40 [0.8068669438362122]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4470 - accuracy: 0.7523 - val_loss: 0.5239 - val_accuracy: 0.7884\n",
      "41 [0.769098699092865]\n",
      "42 [0.8004291653633118]\n",
      "43 [0.794420599937439]\n",
      "44 [0.804291844367981]\n",
      "45 [0.793133020401001]\n",
      "46 [0.790128767490387]\n",
      "47 [0.8051502108573914]\n",
      "48 [0.803004264831543]\n",
      "49 [0.7974249124526978]\n",
      "50 [0.7652360796928406]\n",
      "51 [0.8025751113891602]\n",
      "52 [0.7948498129844666]\n",
      "53 [0.7785407900810242]\n",
      "54 [0.7974249124526978]\n",
      "55 [0.8012875318527222]\n",
      "56 [0.795708179473877]\n",
      "57 [0.7896995544433594]\n",
      "58 [0.7922746539115906]\n",
      "59 [0.775965690612793]\n",
      "60 [0.7965665459632874]\n",
      "61 [0.7798283100128174]\n",
      "62 [0.7918455004692078]\n",
      "63 [0.7909871339797974]\n",
      "64 [0.7965665459632874]\n",
      "65 [0.8008583784103394]\n",
      "66 [0.7909871339797974]\n",
      "67 [0.7914162874221802]\n",
      "68 [0.7914162874221802]\n",
      "69 [0.7854077219963074]\n",
      "70 [0.8047210574150085]\n",
      "71 [0.7918455004692078]\n",
      "72 [0.7939913868904114]\n",
      "73 [0.8051502108573914]\n",
      "74 [0.7978540658950806]\n",
      "75 [0.7914162874221802]\n",
      "76 [0.803004264831543]\n",
      "77 [0.8038626313209534]\n",
      "78 [0.7673819661140442]\n",
      "79 [0.8038626313209534]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 301us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_10(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 80\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_10.BMP\",\"_10.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.44592273235321045]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5681 - accuracy: 0.6919 - val_loss: 0.7107 - val_accuracy: 0.4828\n",
      "1 [0.7326180338859558]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5074 - accuracy: 0.7113 - val_loss: 0.6414 - val_accuracy: 0.6318\n",
      "2 [0.5952789783477783]\n",
      "3 [0.753648042678833]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4911 - accuracy: 0.7215 - val_loss: 0.5751 - val_accuracy: 0.7159\n",
      "4 [0.7416309118270874]\n",
      "5 [0.7347639203071594]\n",
      "6 [0.6879828572273254]\n",
      "7 [0.7656652331352234]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4797 - accuracy: 0.7294 - val_loss: 0.5558 - val_accuracy: 0.7665\n",
      "8 [0.6789699792861938]\n",
      "9 [0.7742488980293274]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4735 - accuracy: 0.7310 - val_loss: 0.5895 - val_accuracy: 0.7017\n",
      "10 [0.7725321650505066]\n",
      "11 [0.7862660884857178]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4723 - accuracy: 0.7333 - val_loss: 0.5337 - val_accuracy: 0.7940\n",
      "12 [0.7806866765022278]\n",
      "13 [0.7862660884857178]\n",
      "14 [0.7600858211517334]\n",
      "15 [0.7755364775657654]\n",
      "16 [0.7656652331352234]\n",
      "17 [0.783261775970459]\n",
      "18 [0.7630901336669922]\n",
      "19 [0.754935622215271]\n",
      "20 [0.793133020401001]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4611 - accuracy: 0.7355 - val_loss: 0.5304 - val_accuracy: 0.7927\n",
      "21 [0.785836935043335]\n",
      "22 [0.7755364775657654]\n",
      "23 [0.7935622334480286]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4548 - accuracy: 0.7432 - val_loss: 0.5347 - val_accuracy: 0.7803\n",
      "24 [0.7721030116081238]\n",
      "25 [0.7896995544433594]\n",
      "26 [0.7991416454315186]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4541 - accuracy: 0.7412 - val_loss: 0.5158 - val_accuracy: 0.7940\n",
      "27 [0.7579399347305298]\n",
      "28 [0.7768240571022034]\n",
      "29 [0.7952789664268494]\n",
      "30 [0.7918455004692078]\n",
      "31 [0.795708179473877]\n",
      "32 [0.7892704010009766]\n",
      "33 [0.7896995544433594]\n",
      "34 [0.7879828214645386]\n",
      "35 [0.7939913868904114]\n",
      "36 [0.7969956994056702]\n",
      "37 [0.8025751113891602]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4480 - accuracy: 0.7477 - val_loss: 0.5194 - val_accuracy: 0.8004\n",
      "38 [0.7961373329162598]\n",
      "39 [0.7892704010009766]\n",
      "40 [0.7961373329162598]\n",
      "41 [0.790128767490387]\n",
      "42 [0.7978540658950806]\n",
      "43 [0.7974249124526978]\n",
      "44 [0.8021458983421326]\n",
      "45 [0.8038626313209534]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4415 - accuracy: 0.7554 - val_loss: 0.5094 - val_accuracy: 0.7906\n",
      "46 [0.7978540658950806]\n",
      "47 [0.7909871339797974]\n",
      "48 [0.785836935043335]\n",
      "49 [0.7918455004692078]\n",
      "50 [0.795708179473877]\n",
      "51 [0.8081545233726501]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4373 - accuracy: 0.7568 - val_loss: 0.5051 - val_accuracy: 0.8030\n",
      "52 [0.8034334778785706]\n",
      "53 [0.808583676815033]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4412 - accuracy: 0.7528 - val_loss: 0.5095 - val_accuracy: 0.8056\n",
      "54 [0.7793991565704346]\n",
      "55 [0.8025751113891602]\n",
      "56 [0.8038626313209534]\n",
      "57 [0.8047210574150085]\n",
      "58 [0.8025751113891602]\n",
      "59 [0.788841187953949]\n",
      "60 [0.8077253103256226]\n",
      "61 [0.808583676815033]\n",
      "62 [0.7969956994056702]\n",
      "63 [0.7935622334480286]\n",
      "64 [0.805579423904419]\n",
      "65 [0.794420599937439]\n",
      "66 [0.7875536680221558]\n",
      "67 [0.7995707988739014]\n",
      "68 [0.8077253103256226]\n",
      "69 [0.7914162874221802]\n",
      "70 [0.805579423904419]\n",
      "71 [0.8038626313209534]\n",
      "72 [0.8094420433044434]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4295 - accuracy: 0.7619 - val_loss: 0.4924 - val_accuracy: 0.8116\n",
      "73 [0.8012875318527222]\n",
      "74 [0.7892704010009766]\n",
      "75 [0.8008583784103394]\n",
      "76 [0.798712432384491]\n",
      "77 [0.800000011920929]\n",
      "78 [0.7978540658950806]\n",
      "79 [0.8051502108573914]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_11(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 80\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_11.BMP\",\"_11.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.42961373925209045]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.5539 - accuracy: 0.6863 - val_loss: 0.6153 - val_accuracy: 0.6567\n",
      "1 [0.6618025898933411]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5033 - accuracy: 0.7125 - val_loss: 0.5736 - val_accuracy: 0.7601\n",
      "2 [0.7527896761894226]\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.4914 - accuracy: 0.7186 - val_loss: 0.5586 - val_accuracy: 0.7678\n",
      "3 [0.7390558123588562]\n",
      "4 [0.7622317671775818]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4800 - accuracy: 0.7300 - val_loss: 0.5432 - val_accuracy: 0.7897\n",
      "5 [0.7729613780975342]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4741 - accuracy: 0.7299 - val_loss: 0.5349 - val_accuracy: 0.7794\n",
      "6 [0.7824034094810486]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4696 - accuracy: 0.7361 - val_loss: 0.5316 - val_accuracy: 0.7854\n",
      "7 [0.7875536680221558]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4677 - accuracy: 0.7386 - val_loss: 0.5212 - val_accuracy: 0.7837\n",
      "8 [0.7768240571022034]\n",
      "9 [0.7935622334480286]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4615 - accuracy: 0.7428 - val_loss: 0.5085 - val_accuracy: 0.7979\n",
      "10 [0.7875536680221558]\n",
      "11 [0.7871244549751282]\n",
      "12 [0.7742488980293274]\n",
      "13 [0.7927038669586182]\n",
      "14 [0.7824034094810486]\n",
      "15 [0.7862660884857178]\n",
      "16 [0.785836935043335]\n",
      "17 [0.7824034094810486]\n",
      "18 [0.7682403326034546]\n",
      "19 [0.785836935043335]\n",
      "20 [0.7978540658950806]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4505 - accuracy: 0.7500 - val_loss: 0.5027 - val_accuracy: 0.7966\n",
      "21 [0.7772532105445862]\n",
      "22 [0.798712432384491]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4520 - accuracy: 0.7478 - val_loss: 0.4911 - val_accuracy: 0.8017\n",
      "23 [0.7965665459632874]\n",
      "24 [0.7991416454315186]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4506 - accuracy: 0.7512 - val_loss: 0.5013 - val_accuracy: 0.7918\n",
      "25 [0.7815450429916382]\n",
      "26 [0.7939913868904114]\n",
      "27 [0.7935622334480286]\n",
      "28 [0.8012875318527222]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4447 - accuracy: 0.7533 - val_loss: 0.4969 - val_accuracy: 0.8030\n",
      "29 [0.7918455004692078]\n",
      "30 [0.8077253103256226]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4406 - accuracy: 0.7565 - val_loss: 0.4865 - val_accuracy: 0.7953\n",
      "31 [0.7935622334480286]\n",
      "32 [0.800000011920929]\n",
      "33 [0.804291844367981]\n",
      "34 [0.7965665459632874]\n",
      "35 [0.7871244549751282]\n",
      "36 [0.793133020401001]\n",
      "37 [0.7854077219963074]\n",
      "38 [0.7995707988739014]\n",
      "39 [0.8051502108573914]\n",
      "40 [0.8008583784103394]\n",
      "41 [0.7905579209327698]\n",
      "42 [0.805579423904419]\n",
      "43 [0.7948498129844666]\n",
      "44 [0.785836935043335]\n",
      "45 [0.7948498129844666]\n",
      "46 [0.7948498129844666]\n",
      "47 [0.7922746539115906]\n",
      "48 [0.7918455004692078]\n",
      "49 [0.793133020401001]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_11(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 50\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_11_1.BMP\", \"_11_1.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.43004292249679565]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.5702 - accuracy: 0.6895 - val_loss: 0.6182 - val_accuracy: 0.6605\n",
      "1 [0.716738224029541]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5400 - accuracy: 0.6983 - val_loss: 0.6094 - val_accuracy: 0.6738\n",
      "2 [0.6733905673027039]\n",
      "3 [0.5248926877975464]\n",
      "4 [0.7579399347305298]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4837 - accuracy: 0.7278 - val_loss: 0.5621 - val_accuracy: 0.7446\n",
      "5 [0.7935622334480286]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4802 - accuracy: 0.7291 - val_loss: 0.5496 - val_accuracy: 0.7614\n",
      "6 [0.7815450429916382]\n",
      "7 [0.7896995544433594]\n",
      "8 [0.7278969883918762]\n",
      "9 [0.7751073241233826]\n",
      "10 [0.7884120345115662]\n",
      "11 [0.7836909890174866]\n",
      "12 [0.7849785685539246]\n",
      "13 [0.7377682328224182]\n",
      "14 [0.7896995544433594]\n",
      "15 [0.7875536680221558]\n",
      "16 [0.7922746539115906]\n",
      "17 [0.7879828214645386]\n",
      "18 [0.7965665459632874]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4524 - accuracy: 0.7516 - val_loss: 0.5131 - val_accuracy: 0.7944\n",
      "19 [0.785836935043335]\n",
      "20 [0.7879828214645386]\n",
      "21 [0.7433476448059082]\n",
      "22 [0.7819742560386658]\n",
      "23 [0.778969943523407]\n",
      "24 [0.7828326225280762]\n",
      "25 [0.7587983012199402]\n",
      "26 [0.785836935043335]\n",
      "27 [0.7729613780975342]\n",
      "28 [0.798712432384491]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4449 - accuracy: 0.7555 - val_loss: 0.4948 - val_accuracy: 0.8017\n",
      "29 [0.795708179473877]\n",
      "30 [0.8017167448997498]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4435 - accuracy: 0.7549 - val_loss: 0.4975 - val_accuracy: 0.7983\n",
      "31 [0.7939913868904114]\n",
      "32 [0.8034334778785706]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4409 - accuracy: 0.7552 - val_loss: 0.5015 - val_accuracy: 0.7987\n",
      "33 [0.7927038669586182]\n",
      "34 [0.7793991565704346]\n",
      "35 [0.793133020401001]\n",
      "36 [0.7927038669586182]\n",
      "37 [0.7991416454315186]\n",
      "38 [0.7922746539115906]\n",
      "39 [0.8017167448997498]\n",
      "40 [0.8008583784103394]\n",
      "41 [0.8017167448997498]\n",
      "42 [0.794420599937439]\n",
      "43 [0.8017167448997498]\n",
      "44 [0.7995707988739014]\n",
      "45 [0.7879828214645386]\n",
      "46 [0.7914162874221802]\n",
      "47 [0.7995707988739014]\n",
      "48 [0.8090128898620605]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4284 - accuracy: 0.7682 - val_loss: 0.4798 - val_accuracy: 0.8017\n",
      "49 [0.8051502108573914]\n",
      "50 [0.8008583784103394]\n",
      "51 [0.8034334778785706]\n",
      "52 [0.7948498129844666]\n",
      "53 [0.7922746539115906]\n",
      "54 [0.8060085773468018]\n",
      "55 [0.8004291653633118]\n",
      "56 [0.7991416454315186]\n",
      "57 [0.8047210574150085]\n",
      "58 [0.8012875318527222]\n",
      "59 [0.8004291653633118]\n",
      "60 [0.7892704010009766]\n",
      "61 [0.795708179473877]\n",
      "62 [0.7952789664268494]\n",
      "63 [0.8004291653633118]\n",
      "64 [0.7952789664268494]\n",
      "65 [0.809871256351471]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4891 - val_accuracy: 0.7897\n",
      "66 [0.7995707988739014]\n",
      "67 [0.798712432384491]\n",
      "68 [0.798712432384491]\n",
      "69 [0.8004291653633118]\n",
      "70 [0.805579423904419]\n",
      "71 [0.8047210574150085]\n",
      "72 [0.7978540658950806]\n",
      "73 [0.8021458983421326]\n",
      "74 [0.8081545233726501]\n",
      "75 [0.803004264831543]\n",
      "76 [0.8068669438362122]\n",
      "77 [0.803004264831543]\n",
      "78 [0.7974249124526978]\n",
      "79 [0.7978540658950806]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_12(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 80\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_12.BMP\", \"_12.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.43047210574150085]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.5455 - accuracy: 0.6983 - val_loss: 0.6224 - val_accuracy: 0.5970\n",
      "1 [0.5562231540679932]\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4973 - accuracy: 0.7167 - val_loss: 0.5986 - val_accuracy: 0.6648\n",
      "2 [0.7008583545684814]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4860 - accuracy: 0.7235 - val_loss: 0.5924 - val_accuracy: 0.7103\n",
      "3 [0.778969943523407]\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.4739 - accuracy: 0.7333 - val_loss: 0.5560 - val_accuracy: 0.7481\n",
      "4 [0.7639485001564026]\n",
      "5 [0.7836909890174866]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4658 - accuracy: 0.7378 - val_loss: 0.5371 - val_accuracy: 0.7910\n",
      "6 [0.793133020401001]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4633 - accuracy: 0.7391 - val_loss: 0.5785 - val_accuracy: 0.7309\n",
      "7 [0.704291820526123]\n",
      "8 [0.766094446182251]\n",
      "9 [0.798712432384491]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4604 - accuracy: 0.7402 - val_loss: 0.5512 - val_accuracy: 0.7455\n",
      "10 [0.7467811107635498]\n",
      "11 [0.7927038669586182]\n",
      "12 [0.770386278629303]\n",
      "13 [0.7776824235916138]\n",
      "14 [0.778969943523407]\n",
      "15 [0.7935622334480286]\n",
      "16 [0.7909871339797974]\n",
      "17 [0.7841201424598694]\n",
      "18 [0.7360514998435974]\n",
      "19 [0.7995707988739014]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4446 - accuracy: 0.7543 - val_loss: 0.5195 - val_accuracy: 0.8013\n",
      "20 [0.7961373329162598]\n",
      "21 [0.795708179473877]\n",
      "22 [0.783261775970459]\n",
      "23 [0.7854077219963074]\n",
      "24 [0.788841187953949]\n",
      "25 [0.770386278629303]\n",
      "26 [0.7304720878601074]\n",
      "27 [0.7978540658950806]\n",
      "28 [0.7939913868904114]\n",
      "29 [0.794420599937439]\n",
      "30 [0.7935622334480286]\n",
      "31 [0.7982832789421082]\n",
      "32 [0.7961373329162598]\n",
      "33 [0.7785407900810242]\n",
      "34 [0.7824034094810486]\n",
      "35 [0.7768240571022034]\n",
      "36 [0.7974249124526978]\n",
      "37 [0.8017167448997498]\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.4324 - accuracy: 0.7666 - val_loss: 0.5078 - val_accuracy: 0.7987\n",
      "38 [0.784549355506897]\n",
      "39 [0.7905579209327698]\n",
      "40 [0.7884120345115662]\n",
      "41 [0.7781115770339966]\n",
      "42 [0.7965665459632874]\n",
      "43 [0.7969956994056702]\n",
      "44 [0.8034334778785706]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4289 - accuracy: 0.7672 - val_loss: 0.5113 - val_accuracy: 0.7961\n",
      "45 [0.8025751113891602]\n",
      "46 [0.7751073241233826]\n",
      "47 [0.8051502108573914]\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.4254 - accuracy: 0.7727 - val_loss: 0.5063 - val_accuracy: 0.7991\n",
      "48 [0.780257523059845]\n",
      "49 [0.8025751113891602]\n",
      "end CNN train\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 71us/step\n",
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 311us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=def_cnn_model_12(height_et,width_et,depth_et)\n",
    "msize=16\n",
    "param1 = 50\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,10,0.1)\n",
    "classify_img_by_batch_res_UDP_modified(model, \"_12_1.BMP\",\"_12_1.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
