{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from PIL import Image,ImageOps,ImageStat,ImageDraw, ImageFilter\n",
    "import os,os.path\n",
    "import sys\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow  import keras as keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "#psp_fileName = \"D:/image_data/__FR1.jpg.BMP._PSP\"\n",
    "#image_fileName = \"D:/image_data/__FR1.jpg.BMP\"\n",
    "#newMask_fileName = \"D:/image_data/new_mask_class_\"\n",
    "#fragm_dir = \"D:/image_data/fragments\"\n",
    "#acc_file = 'D:/image_data/accuracy.txt'\n",
    "#result_fileName = \"D:/image_data/classification_result.BMP\"\n",
    "#marks_filename = 'D:/image_data/class_marks.txt'\n",
    "#img_len = 512\n",
    "#param1 = 25\n",
    "\n",
    "img_file_name = image_fileName\n",
    "#дополнять массив цветами по мере необходимости\\n\",\n",
    "t_color = ['blue', 'red', 'yellow', 'green' , 'violet']\n",
    "temple_file = Image.open(img_file_name)\n",
    "colors = {}\n",
    "#сборка границ прямоугольникв, из которых будут вырезаться области (если их на изображении несколько)\n",
    "classRects=[]\n",
    "curColor = \"\"\n",
    "class_numb = '021'\n",
    "rect_flag  = False\n",
    "load_in_list = False\n",
    "gen_crop_img = False\n",
    "class_amount = 5\n",
    "step_len = 5\n",
    "win_size = step_len * 2 + 1\n",
    "bound = math.ceil(math.sqrt(2) * win_size - win_size)\n",
    "dir_name = fragm_dir\n",
    "\n",
    "img = Image.new('RGB', temple_file.size, color=0)\n",
    "draw = ImageDraw.Draw(img)\n",
    "fp = open(psp_fileName)\n",
    "\n",
    "for k, txt in enumerate(fp):\n",
    "    if k<2:\n",
    "        continue\n",
    "    zz, t = txt.split('=')\n",
    "    if t.find('Pline') >= 0:\n",
    "        x2y = []\n",
    "        rect_flag = False\n",
    "        continue\n",
    "    if t.find('Rectangle') >= 0:\n",
    "        x2y = []\n",
    "        rect_flag = True\n",
    "        continue\n",
    "    if t.find('Pen') >= 0:\n",
    "        p = t.split(',')\n",
    "        curColor = p[2]\n",
    "        if p[2] not in colors:\n",
    "            colors.update({p[2]: len(colors)})\n",
    "    t = t.split(' ')\n",
    "    if t[0] == '':\n",
    "        if rect_flag:\n",
    "            x2y.insert(1, (x2y[0][0], x2y[1][1]))\n",
    "            x2y.append((x2y[2][0], x2y[0][1]))\n",
    "        idx = colors.get(curColor) \n",
    "        if idx ==  len(classRects):\n",
    "            classRects.append([x2y])\n",
    "        else:\n",
    "            classRects[idx].append(x2y)\n",
    "        print(classRects)   \n",
    "        draw.polygon(x2y, outline = t_color[idx], fill = t_color[idx])\n",
    "        continue\n",
    "    x2y.append((int(t[0]), int(t[1])))\n",
    "\n",
    "img.save(newMask_fileName + class_numb +\".BMP\")\n",
    "img.close()\n",
    "fp.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c847450",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "nmb_fragm = 0\n",
    "print(bound)\n",
    "im = Image.open(img_file_name)\n",
    "for i in range(class_amount):\n",
    "    for j in range(len(classRects[i])):\n",
    "        x0 = classRects[i][j][0][0]\n",
    "        y0 = classRects[i][j][0][1]\n",
    "        x_len = classRects[i][j][1][1]-classRects[i][j][0][1]\n",
    "        y_len = classRects[i][j][2][0]-classRects[i][j][1][0]\n",
    "        x_amount = int(x_len/step_len)\n",
    "        y_amount = int(y_len/step_len)\n",
    "        for k in range(x_amount):\n",
    "            for l in range(y_amount):\n",
    "                labels.append(i)\n",
    "                im2 = im.crop((x0 + k * step_len - bound, y0+ l * step_len - bound, x0 + k * step_len +bound + win_size, y0+ l * step_len +bound + win_size))\n",
    "                imfnam = dir_name+\"/+++fragm{:05d}.jpg\".format(nmb_fragm);\n",
    "                nmb_fragm += 1;\n",
    "                im2.save(imfnam)\n",
    "im.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f45918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "temple_file = Image.open(img_file_name)\n",
    "width, height = temple_file.size\n",
    "width_re, height_re = temple_file.size\n",
    "width_re = width_re - width_re % 16\n",
    "height_re = height_re - height_re % 16\n",
    "temple_file.close()\n",
    "\n",
    "if flag_gen == True:\n",
    "    def img_acuumulation_func(resourse_filename, result_filename):\n",
    "        picture = Image.open(resourse_filename)\n",
    "        width_p, height_p = picture.size\n",
    "        width_p = width_p // 2\n",
    "        height_p = height_p // 2\n",
    "        img_accumulated = Image.new('RGB', (width_p, height_p), color=0)\n",
    "        im2 = np.zeros((1, 2, 2, 3), dtype='float32')\n",
    "        for i in range(width_p):\n",
    "            for j in range(height_p):\n",
    "                if (i + 2) < width_p and (j + 2) < height_p:\n",
    "                    im2[0] = np.array(picture.crop((2 * i, 2 * j, 2 * i + 2, j * 2 + 2)))\n",
    "                    color = (im2[0][0, 0] + im2[0][0, 1] + im2[0][1, 1] + im2[0][1, 0])//4\n",
    "                    img_accumulated.putpixel((i, j), (color[0], color[1], color[2]))\n",
    "        img_accumulated.save(result_filename)\n",
    "        img_accumulated.close()\n",
    "        picture.close()\n",
    "\n",
    "\n",
    "    img_acuumulation_func(img_file_name, glob_dir_name + \"accumulated.BMP\")\n",
    "    img_acuumulation_func(glob_dir_name + \"accumulated.BMP\", glob_dir_name + \"accumulated_0.BMP\")\n",
    "    img_acuumulation_func(glob_dir_name + \"accumulated_0.BMP\", glob_dir_name + \"accumulated_1.BMP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_crop_img = True\n",
    "\n",
    "if gen_crop_img:\n",
    "    def croppingFunction(resource_name, width, height, list_file, fragm_dir):\n",
    "        img = Image.open(resource_name)\n",
    "        nmb_fragm = 0\n",
    "        print(width, height)\n",
    "        with open (list_file, 'wt') as file:\n",
    "            for i in range(0, width, step_len - shift_draw):\n",
    "                for j in range(0, height, step_len - shift_draw):\n",
    "                    if(i + win_size) < width and (j + win_size) < height:\n",
    "                        #x2y = [(i, j), (i + win_size, j), (i + win_size, j + win_size), (i, j + win_size)]\n",
    "                        im2 = img.crop((i, j, i + win_size, j + win_size))\n",
    "                        imfnam = fragm_dir + \"+++fragm{:05d}.jpg\".format(nmb_fragm)\n",
    "                        file.write(imfnam + \" \" + str(i) + \" \" + str(j) + \"\\n\")\n",
    "                        nmb_fragm += 1;\n",
    "                        im2.save(imfnam)\n",
    "                    else:\n",
    "                        i_1, j_1 = i, j\n",
    "                        if i + win_size >= width:\n",
    "                            i_1 = width - win_size\n",
    "                        if j + win_size >= height:\n",
    "                            j_1 = height - win_size\n",
    "                        im2 = img.crop((i_1, j_1, i_1 + win_size, j_1 + win_size))\n",
    "                        imfnam = fragm_dir + \"+++fragm{:05d}.jpg\".format(nmb_fragm)\n",
    "                        file.write(imfnam + \" \" + str(i_1) + \" \" + str(j_1) + \"\\n\")\n",
    "                        nmb_fragm += 1;\n",
    "                        im2.save(imfnam)\n",
    "        img.close()\n",
    "\n",
    "    #croppingFunction(img_file_name, width_re, height_re, \"D:/_SAR_Kubinka/list_of_fragments_0.txt\",\n",
    "                 #\"D:/_SAR_Kubinka/cropped_img/_0\")\n",
    "    '''\n",
    "    croppingFunction(glob_dir_name + \"accumulated.BMP\", width_re // 2, height_re // 2,\n",
    "                     \"D:/_SAR_Kubinka/list_of_fragments_1.txt\",\n",
    "                     \"D:/_SAR_Kubinka/cropped_img/_1\")\n",
    "    croppingFunction(glob_dir_name + \"accumulated_0.BMP\", width_re // 4, height_re // 4,\n",
    "                     \"D:/_SAR_Kubinka/list_of_fragments_2.txt\",\n",
    "                     \"D:/_SAR_Kubinka/cropped_img/_2\")\n",
    "    croppingFunction(glob_dir_name + \"accumulated_1.BMP\", width_re // 8, height_re // 8,\n",
    "                     \"D:/_SAR_Kubinka/list_of_fragments_2.txt\",\n",
    "                     \"D:/_SAR_Kubinka/cropped_img/_3\")\n",
    "                     \n",
    "                     '''\n",
    "    croppingFunction(glob_dir_name + \"accumulated_1.BMP\", width_re // 8, height_re // 8,\n",
    "                     \"D:/_SAR_Kubinka/list_of_fragments_3.txt\",\n",
    "                     \"D:/_SAR_Kubinka/cropped_img/_3\")\n",
    "# In[91]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e16e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_in_list = True\n",
    "if load_in_list:\n",
    "    def load_in_list_idx(list_file):\n",
    "        img_list = []\n",
    "        img_coords=[]\n",
    "        with open(list_file, 'r') as file:\n",
    "            for bf in file:\n",
    "                bf_list = bf.split(\" \")\n",
    "                img_list.append(bf_list[0])\n",
    "                img_coords.append((int(bf_list[1]), int(bf_list[2])))\n",
    "        file.close()\n",
    "        return img_list, img_coords\n",
    "\n",
    "\n",
    "    img_list_0, img_coords_0 = load_in_list_idx(\"D:/_SAR_Kubinka/list_of_fragments_0.txt\")\n",
    "    img_list_1, img_coords_1 = load_in_list_idx(\"D:/_SAR_Kubinka/list_of_fragments_1.txt\")\n",
    "    img_list_2, img_coords_2 = load_in_list_idx(\"D:/_SAR_Kubinka/list_of_fragments_2.txt\")\n",
    "    img_list_3, img_coords_3 = load_in_list_idx(\"D:/_SAR_Kubinka/list_of_fragments_3.txt\")\n",
    "# In[102]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#rjkbxtcndj преобразований , выполняемых над изображением\n",
    "transAmount = 6;\n",
    "dlin   = 0\n",
    "\n",
    "def load_CNN_train_augment(dir_name1):\n",
    "    ll = []           #пустой список имен входных файлов JPG\n",
    "    for file in os.listdir(dir_name1):\n",
    "        if file.endswith(\".jpg\"): ll.append(file)\n",
    "    dlin   = len(ll)     \n",
    "    dlin0  = int(len(ll)/2)  #будем пропускать нечетные элементы\n",
    "    train_x = np.zeros((dlin * transAmount, win_size, win_size, 3), dtype='float32')\n",
    "    print('train_x_augm.shape=',train_x.shape)\n",
    "    train_z = np.zeros((dlin * transAmount, 1), dtype='float32')\n",
    "    #dlin = dlin * transAmount\n",
    "    k=0\n",
    "    for file in ll:\n",
    "        im = Image.open(dir_name+\"\\\\\"+file)\n",
    "        train_x[transAmount * k] = np.array(im.crop((bound, bound, bound + win_size, bound + win_size)))*1./255.\n",
    "        train_x[transAmount * k + 1] = np.array(im.rotate(45).crop((bound, bound, bound + win_size,bound + win_size)))*1./255.    #print(b0.shape)\n",
    "        shift0 = random.randint(0,6)\n",
    "        shift1 = random.randint(0,6)\n",
    "        shift2 = random.randint(0,6)\n",
    "        shift3 = random.randint(0,6)\n",
    "        if shift0 == 0 and shift1 == 0:\n",
    "            shift0 += 2\n",
    "        if shift2 == 0 or shift2 == 3:    \n",
    "            shift2 +=1\n",
    "        if shift3 == 0 or shift3 == 3:    \n",
    "            shift3 +=1    \n",
    "        train_x[transAmount * k + 2] = np.array(im.crop((shift0, 0, shift0 + win_size, win_size)))*1./255.    #print(b0.shape)\n",
    "        \n",
    "        train_x[transAmount * k + 3] = np.array(im.crop((0, shift1, win_size, shift1 + win_size)))*1./255.    #print(b0.shape)\n",
    "        train_x[transAmount * k + 4] = np.array(im.rotate(90).crop((shift2, shift3, shift2 + win_size, shift3 + win_size))) * 1./255.\n",
    "        train_x[transAmount * k + 5] = np.array(im.rotate(180).crop((bound, bound, bound + win_size, bound+win_size)))*1./255.\n",
    "        #train_x[transAmount * k + 4] = np.array(im.crop((0,8,13,21)))*1./255.\n",
    "        for p in range(transAmount):\n",
    "            #print(k,p)\n",
    "            train_z[k * transAmount + p] = int(labels[k])\n",
    "\n",
    "        k+=1\n",
    "        if k == dlin: break\n",
    "    temp=[]\n",
    "    for i in range(len(train_z)):\n",
    "        temp.append(to_categorical(train_z[i], num_classes=class_amount))\n",
    "    train_y=np.array(temp)    \n",
    "    return train_x,train_y\n",
    "\n",
    "train_x1,train_y1=load_CNN_train_augment(dir_name)\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "def show_img_data(X_data,K0,rows,cols):   # смотрим на первые rows*cols \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4, 2), dpi=160) #, figsize=(20, 6)) \n",
    "    for j in range(rows):\n",
    "        for k in range(cols):\n",
    "            axes[j,k].set_axis_off()\n",
    "            axes[j,k].imshow(X_data[K0+j*cols+k].squeeze(), cmap='Greys', interpolation='None') #)'auto')\n",
    "\n",
    "show_img_data(train_x1,0,4,8) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_valid = 1000\n",
    "k = 0\n",
    "idx_del = set()\n",
    "train_x_valid = np.zeros((amount_valid, win_size, win_size, 3), dtype='float32')\n",
    "train_y_valid = np.zeros((amount_valid,1,class_amount), dtype='float32')\n",
    "while k <amount_valid:\n",
    "    idx =random.randint(0, train_x1.shape[0]-1)\n",
    "    while idx in idx_del:\n",
    "        idx = random.randint(0, train_x1.shape[0]-1)\n",
    "    idx_del.add(idx)\n",
    "    train_x_valid[k] = train_x1[idx]\n",
    "    train_y_valid[k] = train_y1[idx]\n",
    "    k += 1\n",
    "\n",
    "\n",
    "\n",
    "idx_del = list(idx_del)\n",
    "train_x_data = np.delete(train_x1, idx_del, 0)\n",
    "train_y_data = np.delete(train_y1, idx_del, 0)\n",
    "\n",
    "print('train_x_augm.shape=', train_y_valid.shape)\n",
    "print('train_x_augm.shape=', train_x_data.shape)\n",
    "#реорганизация набора тестовых данных, чтобы была равномерность \n",
    "train_x_valid_buf = np.zeros((train_x_data.shape[0] // 2, win_size, win_size, 3), dtype='float32')\n",
    "train_y_valid_buf = np.zeros((train_x_data.shape[0] // 2, 1, class_amount), dtype='float32')\n",
    "\n",
    "for i in range(train_x_data.shape[0] // 2):\n",
    "    if i % 2 == 0:\n",
    "        train_x_valid_buf[i] = train_x_data[2 * i]\n",
    "        train_y_valid_buf[i] = train_y_data[2 * i]\n",
    "np.flip(train_x_valid_buf)\n",
    "np.flip(train_y_valid_buf)\n",
    "for i in range(train_x_data.shape[0] // 2):\n",
    "    if i % 2 == 0:\n",
    "        train_x_data[2 * i] = train_x_valid_buf[i]\n",
    "        train_y_data[2 * i] = train_y_valid_buf[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_CNN_model_ex(model_t, train_xt, train_yt, dlin_t, msize, step1, step2, val_split):\n",
    "    model_temp = model_t\n",
    "    val_acc_min = 0.0\n",
    "    for k in range(step1):\n",
    "        #model_t.fit(train_xt,train_yt,epochs=step2,verbose=0,batch_size=16,validation_split=0.15)\n",
    "        hist = model_t.fit(train_xt, train_yt.squeeze(), epochs=step2, verbose=0, validation_split=val_split)\n",
    "        vvv = hist.history['val_accuracy']\n",
    "        print(k, vvv)\n",
    "        val_acc = vvv[0]\n",
    "        if val_acc > val_acc_min:\n",
    "            model_temp = model_t\n",
    "            val_acc_min = val_acc\n",
    "            hist = model_t.fit(train_xt, train_yt.squeeze(), epochs=1, verbose=0, validation_split=val_split)\n",
    "\n",
    "    print('end CNN train')\n",
    "    return model_temp\n",
    "\n",
    "\n",
    "# In[106]:\n",
    "\n",
    "\n",
    "\n",
    "num_train, height_data, width_data, depth_data = train_x_data.shape # there are 50000 training examples in CIFAR-10\n",
    "print(num_train, height_data, width_data, depth_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def def_cnn_model_0 (l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 6#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_2)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_1(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 22#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_2(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 25#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes=class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_2)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_3(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 12#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes=class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_4(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 12#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes=class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_5(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 22#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_6(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 22#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='sigmoid')(conv_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_7(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 6#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes=class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_2)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_8(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 6#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes=class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='selu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_2)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_9(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 6#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='sigmoid')(conv_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_2)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def def_cnn_model_10(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 6#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='sigmoid')(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_1)\n",
    "    conv_3 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_2)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    flat = Flatten()(drop_1)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "def def_cnn_model_11(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 15#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation=\"relu\")(inp)\n",
    "    conv_2 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    \n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    conv_3 = Convolution2D(5, kernel_size, kernel_size, border_mode='same', activation=\"relu\")(drop1)\n",
    "    conv_4 = Convolution2D(5, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    \n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    flat = Flatten()(drop_2)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "def def_cnn_model_12(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 15#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(5, kernel_size, kernel_size, border_mode='same', activation=\"relu\")(inp)\n",
    "    conv_2 = Convolution2D(5, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    \n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    conv_3 = Convolution2D(15, kernel_size, kernel_size, border_mode='same', activation=\"relu\")(drop1)\n",
    "    conv_4 = Convolution2D(15, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    \n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    flat = Flatten()(drop_2)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "def def_cnn_model_13(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 15#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(5, kernel_size, kernel_size, border_mode='same')(inp)\n",
    "    conv_2 = Convolution2D(5, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_1)\n",
    "    \n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    conv_3 = Convolution2D(15, kernel_size, kernel_size, border_mode='same')(drop1)\n",
    "    conv_4 = Convolution2D(15, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "    \n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    flat = Flatten()(drop_2)\n",
    "    out = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "\n",
    "\n",
    "def def_cnn_model_14(l_height, l_width, l_depth):\n",
    "    kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "    pool_size = 2 # we will use 2x2 pooling throughout\n",
    "    conv_depth_1 = 15#6#height*2 # we will initially have 32 kernels per conv. layer...\n",
    "    drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "    num_classes = class_amount\n",
    "\n",
    "    inp = Input(shape=(l_height, l_width, l_depth)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(5, kernel_size, kernel_size, border_mode='same')(inp)\n",
    "    conv_2 = Convolution2D(5, kernel_size, kernel_size, border_mode='same')(conv_1)\n",
    "    \n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "    \n",
    "    conv_3 = Convolution2D(15, kernel_size, kernel_size, border_mode='same')(drop1)\n",
    "    conv_4 = Convolution2D(15, kernel_size, kernel_size, border_mode='same')(conv_3)\n",
    "    \n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "    flat = Flatten()(drop_2)\n",
    "    out1 = Dense(15, activation='relu')(flat)\n",
    "    out2 = Dense(15, activation='relu')(out1)\n",
    "    out = Dense(num_classes, activation='softmax')(out2)\n",
    "\n",
    "    l_model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "    l_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "    return l_model\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_creation_funcs = [def_cnn_model_0, def_cnn_model_1,def_cnn_model_2,def_cnn_model_3,\n",
    "                        def_cnn_model_4,def_cnn_model_5,def_cnn_model_6, def_cnn_model_7,\n",
    "                        def_cnn_model_8, def_cnn_model_9, def_cnn_model_10, def_cnn_model_11,\n",
    "                        def_cnn_model_12, def_cnn_model_13, def_cnn_model_14]\n",
    "\n",
    "msize=16 \n",
    "model=model_creation_funcs[idx_model](height_data, width_data, depth_data)\n",
    "\n",
    "model=train_CNN_model_ex(model,train_x_data,train_y_data,dlin,msize, param1,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classification_sequential(model):\n",
    "    image_full = Image.open(img_file_name)\n",
    "    img_new = Image.new('RGB', image_full.size, color=0)\n",
    "    x0 = 0\n",
    "    y0 = 0\n",
    "    draw = ImageDraw.Draw(img_new)\n",
    "    width, height = img_new.size\n",
    "    im2 = np.zeros((1, win_size, win_size, 3), dtype='float32')\n",
    "    class_marks = np.zeros((width, height), dtype='int')\n",
    "    for i in range(0, width, step_len - shift_draw):\n",
    "        for j in range(0, height, step_len - shift_draw):\n",
    "            if(i + win_size) < width and (j + win_size ) < height:\n",
    "                x2y = [(i, j), (i + win_size, j), (i + win_size, j + win_size), (i, j + win_size)]\n",
    "                im2[0] = np.array(image_full.crop((i, j, i + win_size, j + win_size)))*1./255.\n",
    "                z = model.predict(im2, verbose=0)\n",
    "                m_idx = np.argmax(z[0])\n",
    "                for k in range(win_size):\n",
    "                    for l in range(win_size):\n",
    "                        class_marks[i + k, j + l] = m_idx\n",
    "                draw.polygon(x2y, outline=t_color[m_idx], fill=t_color[m_idx])\n",
    "\n",
    "    img_new.save(result_fileName + str(idx_model) + \".BMP\")\n",
    "    img_new.close()\n",
    "\n",
    "\n",
    "def classification_by_batch(model, img_list, img_coords):\n",
    "    temple_file = Image.open(img_file_name)\n",
    "    img_new = Image.new('RGB', temple_file.size, color=0)\n",
    "    draw = ImageDraw.Draw(img_new)\n",
    "    width, height = img_new.size\n",
    "    class_marks = np.zeros((width, height), dtype='int')\n",
    "    batch_size_t = 64\n",
    "    batch_count = 0\n",
    "    batch_pack = np.zeros((batch_size_t, win_size, win_size, 3), dtype='float32')\n",
    "    batch_coords = []\n",
    "    idx_counter = 0\n",
    "\n",
    "    for i in img_list:\n",
    "\n",
    "        if (batch_count < batch_size_t):\n",
    "            im = Image.open(i)\n",
    "            batch_pack[batch_count] = np.array(im) * 1. / 255.\n",
    "            batch_coords.append(img_coords[idx_counter])\n",
    "            batch_count += 1\n",
    "            idx_counter += 1\n",
    "            im.close()\n",
    "        else:\n",
    "            pred_res = model.predict(batch_pack, batch_size=batch_size_t, verbose=0)\n",
    "            for j in range(pred_res.shape[0]):\n",
    "                i_idx = batch_coords[j][0]\n",
    "                j_idx = batch_coords[j][1]\n",
    "                max_idx = np.argmax(pred_res[j])\n",
    "\n",
    "\n",
    "                for k in range(win_size):\n",
    "                    for l in range(win_size):\n",
    "                         class_marks[i_idx + k, j_idx + l] = max_idx\n",
    "                draw.polygon([(i_idx, j_idx), (i_idx + win_size, j_idx), (i_idx + win_size, j_idx + win_size),\n",
    "                                  (i_idx, j_idx + win_size)], outline=t_color[max_idx], fill=t_color[max_idx])\n",
    "            batch_count = 0\n",
    "            batch_coords = []\n",
    "            im = Image.open(i)\n",
    "            batch_pack[batch_count] = np.array(im) * 1. / 255.\n",
    "            batch_coords.append(img_coords[idx_counter])\n",
    "            batch_count += 1\n",
    "            idx_counter += 1\n",
    "            im.close()\n",
    "\n",
    "    img_new.save(result_fileName + str(idx_model) + \".BMP\")\n",
    "    img_new.close()\n",
    "    return class_marks\n",
    "\n",
    "class_marks = classification_by_batch(model, img_list_0, img_coords_0)\n",
    "#class_marks = classification_by_batch(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "if probs_gen == True:\n",
    "\n",
    "    def writing_data_in_qtree(width_re,height_re, resource, result):\n",
    "        temple_file = Image.open(img_file_name)\n",
    "        im2 = np.zeros((1, win_size, win_size, 3), dtype='float32')\n",
    "        class_prbs = np.zeros((width_re, height_re, class_amount), dtype='float32')\n",
    "\n",
    "        for i in range(0, width_re, step_len - shift_draw):\n",
    "            for j in range(0, height_re, step_len - shift_draw):\n",
    "                if (i + win_size) < width_re and (j + win_size) < height_re:\n",
    "                    im2[0] = np.array(temple_file.crop((i, j, i + win_size, j + win_size))) * 1. / 255.\n",
    "                    z = model.predict(im2, verbose=0)\n",
    "                    for k in range(win_size):\n",
    "                        for l in range(win_size):\n",
    "                            for p in range(class_amount):\n",
    "                                class_prbs[i + k, j + l, p] = z[0, p]\n",
    "                else:\n",
    "                    i_1, j_1 = i, j\n",
    "                    if i + win_size >= width_re:\n",
    "                        i_1 = width_re - win_size\n",
    "                    if j + win_size >= height_re:\n",
    "                        j_1 = height_re - win_size\n",
    "                    im2[0] = np.array(temple_file.crop((i_1, j_1, i_1 + win_size, j_1 + win_size))) * 1. / 255.\n",
    "                    z = model.predict(im2, verbose=0)\n",
    "                    for k in range(win_size):\n",
    "                        for l in range(win_size):\n",
    "                            for p in range(class_amount):\n",
    "                                class_prbs[i_1 + k, j_1 + l, p] = z[0, p]\n",
    "        temple_file.close()\n",
    "        with open(result, 'w') as file:\n",
    "            file.write(str(class_amount))\n",
    "            file.write(\"\\n\")\n",
    "            file.write(str(height_re))\n",
    "            file.write(\"\\n\")\n",
    "            for i in range(height_re):\n",
    "                for j in range(width_re):\n",
    "                    for k in range(class_amount):\n",
    "                        file.write(str(class_prbs[j, height_re - i - 1, k]))\n",
    "                        file.write(\" \")\n",
    "                    file.write(\" \")\n",
    "                file.write(\"\\n\")\n",
    "            file.close()\n",
    "        temple_file.close()\n",
    "\n",
    "    def writing_data_in_qtree_by_batch(width_re, height_re, resource, result, img_list, img_coords):\n",
    "        temple_file = Image.open(resource)\n",
    "        im2 = np.zeros((1, win_size, win_size, 3), dtype='float32')\n",
    "        class_prbs = np.zeros((width_re, height_re, class_amount), dtype='float32')\n",
    "\n",
    "        batch_size_t = 64\n",
    "        batch_count = 0\n",
    "        batch_pack = np.zeros((batch_size_t, win_size, win_size, 3), dtype='float32')\n",
    "        batch_coords = []\n",
    "        idx_counter = 0\n",
    "\n",
    "        for img_ptr in img_list:\n",
    "\n",
    "            if (batch_count < batch_size_t):\n",
    "                im = Image.open(img_ptr)\n",
    "                batch_pack[batch_count] = np.array(im) * 1. / 255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "            else:\n",
    "                pred_res = model.predict(batch_pack, batch_size=batch_size_t, verbose=0)\n",
    "                for j_ptr in range(pred_res.shape[0]):\n",
    "                    i = batch_coords[j_ptr][0]\n",
    "                    j = batch_coords[j_ptr][1]\n",
    "                    if (i + win_size) < width_re and (j + win_size) < height_re:\n",
    "                        for k in range(win_size):\n",
    "                            for l in range(win_size):\n",
    "                                for p in range(class_amount):\n",
    "                                    class_prbs[i + k, j + l, p] = pred_res[j_ptr, p]\n",
    "                batch_count = 0\n",
    "                batch_coords = []\n",
    "                im = Image.open(img_ptr)\n",
    "                batch_pack[batch_count] = np.array(im) * 1. / 255.\n",
    "                batch_coords.append(img_coords[idx_counter])\n",
    "                batch_count += 1\n",
    "                idx_counter += 1\n",
    "                im.close()\n",
    "\n",
    "        temple_file.close()\n",
    "        if (batch_count < batch_size_t) and batch_count > 0:\n",
    "            pred_res = model.predict(batch_pack, batch_size=batch_count, verbose=0)\n",
    "            for j_ptr in range(pred_res.shape[0]):\n",
    "                i = batch_coords[j_ptr][0]\n",
    "                j = batch_coords[j_ptr][1]\n",
    "                if (i + win_size) < width_re and (j + win_size) < height_re:\n",
    "                    for k in range(win_size):\n",
    "                        for l in range(win_size):\n",
    "                            for p in range(class_amount):\n",
    "                                class_prbs[i + k, j + l, p] = pred_res[j_ptr, p]\n",
    "        with open(result, 'w') as file:\n",
    "            file.write(str(class_amount))\n",
    "            file.write(\"\\n\")\n",
    "            file.write(str(height_re))\n",
    "            file.write(\"\\n\")\n",
    "            for i_ptr in range(height_re):\n",
    "                for j_ptr in range(width_re):\n",
    "                    for k_ptr in range(class_amount):\n",
    "                        file.write(str(class_prbs[j_ptr, height_re - i_ptr - 1, k_ptr]))\n",
    "                        file.write(\" \")\n",
    "                    file.write(\" \")\n",
    "                file.write(\"\\n\")\n",
    "            file.close()\n",
    "        temple_file.close()\n",
    "\n",
    "\n",
    "    writing_data_in_qtree_by_batch(width_re, height_re, img_file_name, res_filename_0, img_list_0, img_coords_0)\n",
    "    writing_data_in_qtree_by_batch(width_re // 2, height_re // 2, glob_dir_name + \"accumulated.BMP\", res_filename_1, img_list_1, img_coords_1)\n",
    "    writing_data_in_qtree_by_batch(width_re // 4, height_re // 4, glob_dir_name + \"accumulated_0.BMP\", res_filename_2, img_list_2, img_coords_2)\n",
    "    writing_data_in_qtree_by_batch(width_re // 8, height_re // 8, glob_dir_name + \"accumulated_1.BMP\", res_filename_3, img_list_3, img_coords_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c409a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(marks_filename, 'w') as file:\n",
    "    for i in range(height_re):\n",
    "        for j in range(width_re):\n",
    "            file.write(str(class_marks[j, height_re-i] + 1))\n",
    "            file.write(\" \") \n",
    "        file.write(\"\\n\")\n",
    "    file.close()    \n",
    "\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "gridsize = (1, 2)\n",
    "fig = plt.figure(figsize=(18, 16))\n",
    "ax1 = plt.subplot2grid(gridsize, (0, 0))\n",
    "ax2 = plt.subplot2grid(gridsize, (0, 1))\n",
    "data = np.loadtxt(marks_filename)\n",
    "pc = ax1.contourf(data)\n",
    "plt.colorbar(pc, ax=ax1, format='$%d')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
